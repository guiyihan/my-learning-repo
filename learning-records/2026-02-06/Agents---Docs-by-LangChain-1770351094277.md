# Agents - Docs by LangChain

> ğŸ“… è®°å½•æ—¶é—´: 2026/2/6 12:11:34
> ğŸ”— æ¥æº: [Agents - Docs by LangChain](https://docs.langchain.com/oss/python/langchain/agents)

## AIæ€»ç»“

# LangChain Agents æ–‡æ¡£åˆ†ææ€»ç»“

## 1. æ ¸å¿ƒä¸»é¢˜

è¿™æ˜¯ LangChain æ¡†æ¶ä¸­å…³äº **Agentsï¼ˆæ™ºèƒ½ä»£ç†ï¼‰** çš„å®˜æ–¹æ–‡æ¡£ï¼Œä¸»è¦ä»‹ç»å¦‚ä½•ä½¿ç”¨ `create_agent` å‡½æ•°åˆ›å»ºèƒ½å¤Ÿè‡ªä¸»æ¨ç†ã€é€‰æ‹©å·¥å…·å¹¶è¿­ä»£è§£å†³é—®é¢˜çš„ AI ç³»ç»Ÿã€‚Agents ç»“åˆäº†è¯­è¨€æ¨¡å‹å’Œå·¥å…·ï¼ŒåŸºäº LangGraph æ„å»ºå›¾ç»“æ„çš„è¿è¡Œæ—¶ç¯å¢ƒã€‚

## 2. å…³é”®è¦ç‚¹

### â­ Agent çš„æ ¸å¿ƒæœºåˆ¶
- **ReAct æ¨¡å¼**ï¼šAgent éµå¾ª"æ¨ç†+è¡ŒåŠ¨"å¾ªç¯æ¨¡å¼ï¼ˆReasoning + Actingï¼‰
- å·¥ä½œæµç¨‹ï¼šæ¥æ”¶è¾“å…¥ â†’ æ¨¡å‹æ¨ç† â†’ è°ƒç”¨å·¥å…· â†’ è§‚å¯Ÿç»“æœ â†’ ç»§ç»­æ¨ç† â†’ è¾“å‡ºæœ€ç»ˆç­”æ¡ˆ
- åŸºäºå›¾ç»“æ„ï¼ˆèŠ‚ç‚¹+è¾¹ï¼‰è¿è¡Œï¼ŒåŒ…æ‹¬æ¨¡å‹èŠ‚ç‚¹ã€å·¥å…·èŠ‚ç‚¹å’Œä¸­é—´ä»¶

### â­ ä¸‰å¤§æ ¸å¿ƒç»„ä»¶

1. **Modelï¼ˆæ¨¡å‹ï¼‰**
   - é™æ€æ¨¡å‹ï¼šåˆ›å»ºæ—¶é…ç½®ï¼Œæ‰§è¡ŒæœŸé—´ä¸å˜
   - åŠ¨æ€æ¨¡å‹ï¼šåŸºäºä¸Šä¸‹æ–‡è¿è¡Œæ—¶é€‰æ‹©ï¼ˆå¦‚æ ¹æ®å¯¹è¯å¤æ‚åº¦åˆ‡æ¢ï¼‰

2. **Toolsï¼ˆå·¥å…·ï¼‰**
   - æ”¯æŒé¡ºåºè°ƒç”¨ã€å¹¶è¡Œè°ƒç”¨
   - å†…ç½®é”™è¯¯å¤„ç†å’Œé‡è¯•é€»è¾‘
   - å¯åŠ¨æ€è¿‡æ»¤æˆ–æ³¨å†Œå·¥å…·

3. **System Promptï¼ˆç³»ç»Ÿæç¤ºï¼‰**
   - å¯é™æ€é…ç½®æˆ–é€šè¿‡ä¸­é—´ä»¶åŠ¨æ€ç”Ÿæˆ
   - æ”¯æŒé«˜çº§åŠŸèƒ½ï¼ˆå¦‚ Anthropic çš„æç¤ºç¼“å­˜ï¼‰

### â­ é«˜çº§ç‰¹æ€§

- **ç»“æ„åŒ–è¾“å‡º**ï¼šé€šè¿‡ `ToolStrategy` æˆ– `ProviderStrategy` å¼ºåˆ¶ç‰¹å®šæ ¼å¼è¾“å‡º
- **è®°å¿†ç®¡ç†**ï¼šè‡ªåŠ¨ç»´æŠ¤å¯¹è¯å†å²ï¼Œæ”¯æŒè‡ªå®šä¹‰çŠ¶æ€æ¨¡å¼
- **ä¸­é—´ä»¶ç³»ç»Ÿ**ï¼šç”¨äºåŠ¨æ€æ¨¡å‹é€‰æ‹©ã€å·¥å…·è¿‡æ»¤ã€é”™è¯¯å¤„ç†ç­‰

### â­ çµæ´»çš„é…ç½®æ–¹å¼

- æ”¯æŒæ¨¡å‹æ ‡è¯†ç¬¦å­—ç¬¦ä¸²ï¼ˆå¦‚ `"openai:gpt-5"`ï¼‰
- æ”¯æŒç›´æ¥å®ä¾‹åŒ–æ¨¡å‹ç±»ä»¥ç²¾ç¡®æ§åˆ¶å‚æ•°
- å·¥å…·å¯ç”¨æ™®é€š Python å‡½æ•°æˆ–åç¨‹å®šä¹‰

## 3. é‡è¦ç»†èŠ‚

### ğŸ”§ æŠ€æœ¯ç»†èŠ‚
- **å·¥å…·è£…é¥°å™¨**ï¼šä½¿ç”¨ `@tool` è£…é¥°å™¨è‡ªå®šä¹‰å·¥å…·å±æ€§
- **ä¸­é—´ä»¶è£…é¥°å™¨**ï¼š
  - `@wrap_model_call`ï¼šåŒ…è£…æ¨¡å‹è°ƒç”¨
  - `@wrap_tool_call`ï¼šå¤„ç†å·¥å…·æ‰§è¡Œ
  - `@dynamic_prompt`ï¼šåŠ¨æ€ç”Ÿæˆç³»ç»Ÿæç¤º

### âš ï¸ æ³¨æ„äº‹é¡¹
- ä½¿ç”¨ç»“æ„åŒ–è¾“å‡ºæ—¶ï¼Œä¸æ”¯æŒé¢„ç»‘å®šå·¥å…·çš„æ¨¡å‹ï¼ˆpre-bound modelsï¼‰
- ç©ºå·¥å…·åˆ—è¡¨ä¼šåˆ›å»ºä»…å« LLM èŠ‚ç‚¹çš„ agentï¼ˆæ— å·¥å…·è°ƒç”¨èƒ½åŠ›ï¼‰
- è‡ªå®šä¹‰çŠ¶æ€æ¨¡å¼å¿…é¡»ç»§æ‰¿ `AgentState` ä½œä¸º `TypedDict`

### ğŸ“Š ä»£ç ç¤ºä¾‹æ¨¡å¼
```python
# åŸºç¡€åˆ›å»º
agent = create_agent("openai:gpt-5", tools=tools)

# å¸¦ä¸­é—´ä»¶çš„é«˜çº§é…ç½®
agent = create_agent(
    model=model,
    tools=tools,
    system_prompt="...",
    middleware=[custom_middleware],
    response_format=ProviderStrategy(Schema)
)

# è°ƒç”¨
result = agent.invoke({
    "messages": [{"role": "user", "content": "query"}]
})
```

## 4. ä¸ªäººå­¦ä¹ ä»·å€¼

### ğŸ’¡ æŠ€æœ¯å¯å‘

1. **æ¨¡å—åŒ–è®¾è®¡æ€æƒ³**ï¼šæ¨¡å‹ã€å·¥å…·ã€æç¤ºè¯ä¸‰è€…è§£è€¦ï¼Œé€šè¿‡ä¸­é—´ä»¶çµæ´»ç»„åˆï¼Œæ˜¯ä¼˜ç§€çš„æ¶æ„è®¾è®¡èŒƒä¾‹

2. **ReAct æ¨¡å¼ç†è§£**ï¼šè¿™æ˜¯æ„å»ºè‡ªä¸» AI ç³»ç»Ÿçš„æ ¸å¿ƒèŒƒå¼ï¼Œç†è§£"è§‚å¯Ÿ-æ¨ç†-è¡ŒåŠ¨"å¾ªç¯å¯¹å¼€å‘æ™ºèƒ½åº”ç”¨è‡³å…³é‡è¦

3. **åŠ¨æ€é…ç½®èƒ½åŠ›**ï¼šå­¦ä¼šåœ¨è¿è¡Œæ—¶æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´æ¨¡å‹ã€å·¥å…·å’Œæç¤ºè¯ï¼Œå¯æ˜¾è‘—æå‡ç³»ç»Ÿçš„é€‚åº”æ€§å’Œæˆæœ¬æ•ˆç›Š

### ğŸ¯ å®è·µåº”ç”¨åœºæ™¯

- **ä¼ä¸šçº§åº”ç”¨**ï¼šæƒé™æ§åˆ¶ï¼ˆåŠ¨æ€å·¥å…·è¿‡æ»¤ï¼‰ã€å¤šç§Ÿæˆ·åœºæ™¯ï¼ˆåŠ¨æ€æç¤ºè¯ï¼‰
- **æˆæœ¬ä¼˜åŒ–**ï¼šæ ¹æ®ä»»åŠ¡å¤æ‚åº¦åˆ‡æ¢ä¸åŒä»·ä½çš„æ¨¡å‹
- **å¯é æ€§æå‡**ï¼šç»Ÿä¸€çš„é”™è¯¯å¤„ç†ã€å·¥å…·é‡è¯•æœºåˆ¶

### ğŸ“š å­¦ä¹ å»ºè®®

1. å…ˆæŒæ¡åŸºç¡€ç”¨æ³•ï¼ˆé™æ€æ¨¡å‹+ç®€å•å·¥å…·ï¼‰
2. æ·±å…¥ç†è§£ ReAct å¾ªç¯çš„æ‰§è¡Œæµç¨‹
3. é€æ­¥å­¦ä¹ ä¸­é—´ä»¶ç³»ç»Ÿå®ç°é«˜çº§åŠŸèƒ½
4. å…³æ³¨ç»“æ„åŒ–è¾“å‡ºåœ¨å®é™…ä¸šåŠ¡ä¸­çš„åº”ç”¨

è¿™ä»½æ–‡æ¡£æ˜¯æ„å»ºç”Ÿäº§çº§ AI Agent çš„å®Œæ•´æŒ‡å—ï¼Œå€¼å¾—åå¤ç ”è¯»å¹¶ç»“åˆå®é™…é¡¹ç›®å®è·µã€‚

## åŸæ–‡æ‘˜å½•

Skip to main contentDocs by LangChain home pageOpen sourceSearch...NavigationCore componentsAgentsCore componentsAgentsCopy pageAgents combine language models with tools to create systems that can reason about tasks, decide which tools to use, and iteratively work towards solutions. create_agent provides a production-ready agent implementation. An LLM Agent runs tools in a loop to achieve a goal. An agent runs until a stop condition is met - i.e., when the model emits a final output or an iteration limit is reached. actionobservationfinishinputmodeltoolsoutput create_agent builds a graph-based agent runtime using LangGraph. A graph consists of nodes (steps) and edges (connections) that define how your agent processes information. The agent moves through this graph, executing nodes like the model node (which calls the model), the tools node (which executes tools), or middleware.Learn more about the Graph API. â€‹Core components â€‹Model The model is the reasoning engine of your agent. It can be specified in multiple ways, supporting both static and dynamic model selection. â€‹Static model Static models are configured once when creating the agent and remain unchanged throughout execution. This is the most common and straightforward approach. To initialize a static model from a model identifier string: Copyfrom langchain.agents import create_agent agent = create_agent("openai:gpt-5", tools=tools) Model identifier strings support automatic inference (e.g., "gpt-5" will be inferred as "openai:gpt-5"). Refer to the reference to see a full list of model identifier string mappings. For more control over the model configuration, initialize a model instance directly using the provider package. In this example, we use ChatOpenAI. See Chat models for other available chat model classes. Copyfrom langchain.agents import create_agent from langchain_openai import ChatOpenAI model = ChatOpenAI( model="gpt-5", temperature=0.1, max_tokens=1000, timeout=30 # ... (other params) ) agent = create_agent(model, tools=tools) Model instances give you complete control over configuration. Use them when you need to set specific parameters like temperature, max_tokens, timeouts, base_url, and other provider-specific settings. Refer to the reference to see available params and methods on your model. â€‹Dynamic model Dynamic models are selected at runtime based on the current state and context. This enables sophisticated routing logic and cost optimization. To use a dynamic model, create middleware using the @wrap_model_call decorator that modifies the model in the request: Copyfrom langchain_openai import ChatOpenAI from langchain.agents import create_agent from langchain.agents.middleware import wrap_model_call, ModelRequest, ModelResponse basic_model = ChatOpenAI(model="gpt-4.1-mini") advanced_model = ChatOpenAI(model="gpt-4.1") @wrap_model_call def dynamic_model_selection(request: ModelRequest, handler) -> ModelResponse: """Choose model based on conversation complexity.""" message_count = len(request.state["messages"]) if message_count > 10: # Use an advanced model for longer conversations model = advanced_model else: model = basic_model return handler(request.override(model=model)) agent = create_agent( model=basic_model, # Default model tools=tools, middleware=[dynamic_model_selection] ) Pre-bound models (models with bind_tools already called) are not supported when using structured output. If you need dynamic model selection with structured output, ensure the models passed to the middleware are not pre-bound. For model configuration details, see Models. For dynamic model selection patterns, see Dynamic model in middleware. â€‹Tools Tools give agents the ability to take actions. Agents go beyond simple model-only tool binding by facilitating: Multiple tool calls in sequence (triggered by a single prompt) Parallel tool calls when appropriate Dynamic tool selection based on previous results Tool retry logic and error handling State persistence across tool calls For more information, see Tools. â€‹Defining tools Pass a list of tools to the agent. Tools can be specified as plain Python functions or coroutines.The tool decorator can be used to customize tool names, descriptions, argument schemas, and other properties. Copyfrom langchain.tools import tool from langchain.agents import create_agent @tool def search(query: str) -> str: """Search for information.""" return f"Results for: {query}" @tool def get_weather(location: str) -> str: """Get weather information for a location.""" return f"Weather in {location}: Sunny, 72Â°F" agent = create_agent(model, tools=[search, get_weather]) If an empty tool list is provided, the agent will consist of a single LLM node without tool-calling capabilities. â€‹Tool error handling To customize how tool errors are handled, use the @wrap_tool_call decorator to create middleware: Copyfrom langchain.agents import create_agent from langchain.agents.middleware import wrap_tool_call from langchain.messages import ToolMessage

[å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­...]

---

*ç”±æ™ºèƒ½å­¦ä¹ åŠ©æ‰‹è‡ªåŠ¨ç”Ÿæˆ*
